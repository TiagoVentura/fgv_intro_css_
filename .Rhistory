summarize(polarity=mean(polarity)) %>%
arrange(polarity)
library(reshape2)
library(wordcloud)
tidy_discursos_sent %>%
filter(polarity!=0) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 200)
part_pol <- discursos %>%
mutate(id_discursos=1:nrow(.)) %>%
left_join(tidy_dicursos_av) %>%
mutate(polarity_binary=ifelse(polarity>0,"Positivo", "Negativo"),)%>%
count(partido, polarity_binary) %>%
mutate(n=ifelse(polarity_binary=="Negativo", -1*n, n)) %>%
filter(partido!="\n",
n!=0) %>%
arrange(polarity_binary, n) %>%
mutate(partido=fct_inorder(partido))
# Graph
ggplot(part_pol,
aes(x = partido, y = n, fill = polarity_binary)) +
geom_col(alpha=.6, color="black") +
coord_flip() +
scale_fill_manual(values=c("#5BBCD6","#FF0000"),
name="Polaridade em \n Discursos Legislativos") +
labs(x="Partidos", y="Numero de Discursos") +
theme_bw() +
theme(legend.position = "bottom")
library(rtweet)
library(tidyverse)
bolsonaro_tweets<-search_tweets("bolsonaro", n=50, include_rts = TRUE)
# Veja os dados
bolsonaro_tweets
# Selecionar somente o texto
bolsonaro_tweets <- bolsonaro_tweets %>%
select(user_id, screen_name, text)
# Veja os dados
bolsonaro_tweets
# Salvar como objeto de R
save(bolsonaro_tweets,file="bolsonaro_tweets.Rdata")
rm(bolsonaro_tweets)
bolsonaro_tweets
load("bolsonaro_tweets.Rdata")
bolsonaro_tweets
# Ver arquivos
list.files("data_txt")
# Ver arquivos
list.files("data_txt")
# Salvar nomes
nomes <- list.files("data_txt")
nomes
# Criar endereço completo
path <- paste0("data_txt/", nomes)
path
# Abrir
read_lines(path[1])
# Abrir
discurso1 <- read_lines(path[1])
discurso1
bolsonaro_tweets<-search_tweets("bolsonaro", n=50, include_rts = TRUE)
bolsonaro_tweets
path
# Abrir
#discurso1 <- read_lines(path[1])
dados <- map_chr(path, read_lines)
dados
dados <- tibble(file=nomes, texto=dados)
dados
discursos <- read_csv("speeches.csv")
discursos
library(tidytext)
discursos %>% slice(1:10)
# Convertendo para o formato tidy.
tidy_discursos <- discursos %>%
mutate(id_discursos=1:nrow(.)) %>%
unnest_tokens(words, speech) #(output, input)
tidy_discursos %>% slice(1:100)
discursos
discursos %>%
unnest_tokens(words, speech, token="sentences") #(output, input)
tidy_discursos %>%
group_by(id_discursos)
tidy_discursos <- tidy_discursos %>%
group_by(id_discursos) %>%
mutate(total_palavras=n()) %>%
ungroup()
tidy_discursos
partido_st <- discursos %>%
group_by(partido) %>%
summarise(n_partidos=n())
partido_st
nome_st <- discursos %>%
group_by(nome) %>%
summarise(n_dep=n())
uf_st <- discursos %>%
group_by(uf) %>%
summarise(n_uf=n())
nome_st
tidy_discursos <- left_join(tidy_discursos, partido_st) %>%
left_join(nome_st) %>%
left_join(uf_st)
tidy_discursos
library(stopwords)
stopwords("portuguese")
stop_words <- tibble(words=stopwords("portuguese"))
stop_words
# Elimina com um Join
dim(tidy_discursos)
tidy_discursos <- tidy_discursos %>%
anti_join(stop_words)
dim(tidy_di)
dim(tidy_discursos)
estados <- tibble(words=unique(str_to_lower(tidy_discursos$uf)))
estados
# Elimina com um Join
tidy_discursos <- tidy_discursos %>%
anti_join(estados)
dim(tidy_discursos)
function_names <- tibble(words=c("candidato", "candidata", "brasileira", "brasileiro",
"câmara", "municipio",
"municipal", "eleições", "cidade", "partido",
"cidadão", "deputado", "deputada", "caro", "cara",
"plano", "suplementar",
"voto","votar", "eleitor", "querido",
"sim", "não", "dia", "hoje", "amanhã", "amigo", "amiga",
"seção", "emenda", "i", "ii", "iii", "iv",
"colegas", "clausula", "prefeit*", "presidente",
"prefeitura", 'proposta','propostas','meta',
'metas','plano','governo','municipal','candidato',
'diretrizes','programa', "deputados", "federal",
'eleição','coligação','município', "senhor", "sr", "dr",
"excelentissimo", "nobre", "deputad*", "srs", "sras", "v.exa",
"san", "arial", "sentido", "fim", "minuto", "razão", "v.exa",
"país", "brasil", "tribuna", "congresso", "san", "symbol", "sans", "serif",
"ordem", "revisão", "orador", "obrigado", "parte", "líder", "bloco", "esc",
"sra", "oradora", "bloco", "times", "new", "colgano", "pronuncia", "colega",
"presidenta", "pronunciamento", "mesa", "parlamentares", "secretário", "seguinte",
"discurso","mato", "sul", "norte", "nordeste", "sudeste", "centro-oeste", "sul", "grosso",
"é", "ser", "casa", "todos", "sobre", "aqui", "nacional"))
tidy_discursos <- tidy_discursos %>%
anti_join(function_names)
dim(tidy_discursos)
tidy_discursos <- tidy_discursos %>%
mutate(words=str_remove_all(words, "[[:digit:]]"),
words=str_remove_all(words, "[:punct:]"))
dim(tidy_discursos)
tidy_discursos <- tidy_discursos %>%
mutate(words=str_trim(words),
words=str_squish(words),
words=stringi::stri_trans_general(words, "Latin-ASCII"))%>%
filter(words!="")
dim(tidy_discursos)
tidy_discursos %>%
count(words, sort = TRUE)
tidy_discursos %>%
count(words, sort = TRUE) %>%
slice(1:25) %>%
mutate(word = reorder(words, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
theme_minimal()
# Gráfico
tidy_discursos %>%
count(words, sort = TRUE) %>%
slice(1:25) %>%
mutate(word = reorder(words, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL) +
theme_minimal()
library(scales)
tidy_discursos %>%
select(partido, total_palavras) %>%
distinct()
# Total palavras por partido
total_palavras <- tidy_discursos %>%
select(partido, total_palavras) %>%
distinct() %>%
group_by(partido) %>%
summarize(total_words_per_party=sum(total_palavras)) %>%
filter(partido%in%c("PT", "PSDB"))
total_palavras
tidy_discursos %>%
count(partido, words)
# Soma cada palavra por partido
palavras_partido <- tidy_discursos %>%
count(partido, words) %>%
filter(partido%in%c("PT", "PSDB"))
palavras_partido
# Merge
partidos <- left_join(palavras_partido, total_palavras) %>%
mutate(prop=n/total_words_per_party) %>%
#untidy
select(words, partido, prop) %>%
pivot_wider(names_from=partido,
values_from=prop) %>%
drop_na() %>%
mutate(more=ifelse(PT>PSDB, "More PT", "More PSDB"))
partidos
ggplot(partidos, aes(x = PSDB, y = PT,
alpha = abs(PT - PSDB),
color=more)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = words), check_overlap = TRUE, vjust = 1.5, alpha=.8) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_manual(values=c("#5BBCD6","#FF0000"), name="") +
theme(legend.position="none") +
labs(y = "Proportion of Words (PT)", x = "Proportion of Words (PSDB)") +
theme_minimal()
# Usaremos este dicionário.
#devtools::install_github("sillasgonzaga/lexiconPT")
library(lexiconPT)
# Ver Dicionario
data("sentiLex_lem_PT02")
sent_pt <- as_tibble(sentiLex_lem_PT02)
sent_pt
tidy_discursos <- left_join(tidy_discursos, sent_pt, by=c("words"="term"))
tidy_discursos
# clean words with no sentiment
tidy_discursos_sent <- tidy_discursos %>%
mutate(polarity=ifelse(is.na(polarity), 0, polarity)) %>%
filter(polarity!=7)
# sentimento por discursos
tidy_dicursos_av <- tidy_discursos_sent %>%
group_by(id_discursos) %>%
summarize(polarity=mean(polarity)) %>%
arrange(polarity)
tidy_discursos_av
tidy_dicursos_av
tidy_dicursos_av
library(reshape2)
library(wordcloud)
tidy_discursos_sent %>%
filter(polarity!=0) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 200)
tidy_discursos_sent %>%
filter(polarity!=0) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE)
tidy_discursos_sent %>%
filter(polarity!=0) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0)
tidy_discursos_sent %>%
filter(polarity!=0) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 200)
tidy_discursos_sent
tidy_discursos_sent %>%
filter(polarity!=0, partido=="PT" ) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 200)
tidy_discursos_sent %>%
filter(polarity!=0, partido=="PSDB" ) %>%
mutate(polarity=ifelse(polarity==1, "Positiva", "Negativa")) %>%
count(words, polarity, sort = TRUE) %>%
acast(words ~ polarity, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("blue", "steelblue"),
max.words = 200)
part_pol <- discursos %>%
mutate(id_discursos=1:nrow(.)) %>%
left_join(tidy_dicursos_av) %>%
mutate(polarity_binary=ifelse(polarity>0,"Positivo", "Negativo"))%>%
count(partido, polarity_binary) %>%
mutate(n=ifelse(polarity_binary=="Negativo", -1*n, n)) %>%
filter(partido!="\n",
n!=0) %>%
arrange(polarity_binary, n) %>%
mutate(partido=fct_inorder(partido))
discursos
part_pol <- discursos %>%
mutate(id_discursos=1:nrow(.)) %>%
left_join(tidy_dicursos_av) %>%
mutate(polarity_binary=ifelse(polarity>0,"Positivo", "Negativo"))%>%
count(partido, polarity_binary) %>%
mutate(n=ifelse(polarity_binary=="Negativo", -1*n, n)) %>%
filter(partido!="\n",
n!=0) %>%
arrange(polarity_binary, n) %>%
mutate(partido=fct_inorder(partido))
part_pol
# Graph
ggplot(part_pol,
aes(x = partido, y = n, fill = polarity_binary)) +
geom_col(alpha=.6, color="black") +
coord_flip() +
scale_fill_manual(values=c("#5BBCD6","#FF0000"),
name="Polaridade em \n Discursos Legislativos") +
labs(x="Partidos", y="Numero de Discursos") +
theme_bw() +
theme(legend.position = "bottom")
# Graph
ggplot(part_pol,
aes(x = partido, y = n, fill = polarity_binary)) +
geom_col(alpha=.6, color="black") +
coord_flip() +
scale_fill_manual(values=c("#FF0000", "#5BBCD6"),
name="Polaridade em \n Discursos Legislativos") +
labs(x="Partidos", y="Numero de Discursos") +
theme_bw() +
theme(legend.position = "bottom")
blogdown::serve_site()
# Packages
library(tidyverse)
library(extrafont)
library(here)
library(ggalt)
library(lubridate)
# ggplot theme ------------------------------------------------------------
my_font <- "Palatino Linotype"
my_bkgd <- "white"
#my_bkgd <- "#f5f5f2"
pal <- RColorBrewer::brewer.pal(9, "Spectral")
my_theme <- theme(text = element_text(family = my_font, color = "#22211d"),
rect = element_rect(fill = my_bkgd),
plot.background = element_rect(fill = my_bkgd, color = NA),
panel.background = element_rect(fill = my_bkgd, color = NA),
panel.border = element_rect(color="black"),
strip.background = element_rect(color="black", fill="white"),
legend.background = element_rect(fill = my_bkgd, color = NA),
legend.key = element_rect(size = 6, fill = "white", colour = NA),
legend.key.size = unit(1, "cm"),
legend.text = element_text(size = 14, family = my_font),
legend.title = element_text(size=14),
plot.title = element_text(size = 22, face = "bold"),
plot.subtitle = element_text(size=16, family=my_font),
axis.title= element_text(size=22),
axis.text = element_text(size=14),
axis.title.x = element_text(hjust=1),
strip.text = element_text(family = my_font, color = "#22211d",
size = 16, face="italic"),
plot.caption = element_text(size=12, family=my_font),
plot.margin =  unit(c(1,1,1,1), "cm"))
theme_set(theme_bw() + my_theme)
# Open data ---------------------------------------------------------------
library("margins")
x <- lm(mpg ~ cyl * hp + wt, data = mtcars)
(m <- margins(x))
summary(m)
getwd()
list.files(here("pipeline_phd"))
library(ggtext)
tm <- read_csv("/home/venturat/Dropbox/pipeline_phd/pipeline_phd_2.csv")
tm <- tm %>%
mutate(across(c(submission, response), ~
ifelse(is.na(.x), "01-01-2021", .x))) %>%
mutate(across(c(submission, response), mdy)) %>%
mutate(Papers=fct_inorder(Papers)) %>%
mutate(decision=fct_relevel(decision,
"Accepted", "Second Review", "First Review", "R&R", "Under Review", "Reject")) %>%
group_by(Papers) %>%
mutate(accepted=ifelse(decision=="Accepted", TRUE, FALSE),
accepted=sum(accepted)) %>%
ungroup() %>%
mutate(papers_label=ifelse(accepted==1,
glue::glue("<b style='color:#D3DDDC'>{Papers}</b>"),
glue::glue("<b style='color:#FF0000'>{Papers}</b>")))
ggplot(tm, aes(y=fct_rev(Papers), x=submission, xend=response,
fill=fct_rev(decision),
label=Journals)) +
geom_dumbbell(size=3, shape=21, color="gray90") +
# geom_point(data=tm %>% filter(!is.na(accepted)),
#           aes(x=response, y=fct_rev(Papers)),
#          shape=23, fill="steelblue", size=3) +
labs(x=NULL, y=NULL,
title="Submissions Pipeline during the Ph.D.",
subtitle = "With Start Dates, Response Dates, Decision and Journals") +
ggrepel::geom_label_repel(nudge_y = -.4,
show.legend = FALSE,
fill="white") +
scale_x_date(breaks="2 months", date_labels = "%b-%y",
limits = c(as.Date("2019-05-16"), as.Date("2021-05-30"))) +
scale_fill_brewer(palette="RdBu", name="") +
theme(legend.position = "bottom",
panel.border = element_blank(),
panel.grid = element_line(linetype = "dashed")) +
geom_segment(y= 5, yend=5, x=0, xend=50, color="red") +
theme(axis.text.y = element_markdown()) +
scale_y_discrete(labels=rev(unique(tm$papers_label)))
1000*500
library(rtweet)
d <- get_timelines("_Tiagoventura", n=100)
d
list_usarios <- list("_Tiagoventura", "DaniCamp0")
# clean
d <- d %>%
View(d)
View(d)
d$is_quote
# collect tweets
d <- get_timelines("_Tiagoventura", n=100)
d$is_quote
d
# clean
d <- d %>%
filter(str_detect(text, "@"))
d
d$text[[5]]
# collect tweets
d <- get_timelines("_Tiagoventura", n=100)
# clean
d_red <- d %>%
filter(str_detect(text, "@"))
# save
dim(d)
dim(d_red)
?get_timelines
?get_timeline
collect_tweets <- function(name){
# collect tweets
d <- get_timelines(name, n=100)
# clean
d <- d %>%
filter(str_detect(text, "@"))
# Save
return(d)
}
list_d <- map(list_usarios, collect_tweets)
list_d
bind_rows(list_d)
ggplot(tm, aes(y=fct_rev(Papers), x=submission, xend=response,
fill=fct_rev(decision),
label=Journals)) +
geom_dumbbell(size=3, shape=21, color="gray90") +
# geom_point(data=tm %>% filter(!is.na(accepted)),
#           aes(x=response, y=fct_rev(Papers)),
#          shape=23, fill="steelblue", size=3) +
labs(x=NULL, y=NULL,
title="Submissions Pipeline during the Ph.D.",
subtitle = "With Start Dates, Response Dates, Decision and Journals") +
ggrepel::geom_label_repel(nudge_y = -.4,
show.legend = FALSE,
fill="white") +
scale_x_date(breaks="2 months", date_labels = "%b-%y",
limits = c(as.Date("2019-05-16"), as.Date("2021-05-30"))) +
scale_fill_brewer(palette="RdBu", name="") +
theme(legend.position = "bottom",
panel.border = element_blank(),
panel.grid = element_line(linetype = "dashed")) +
geom_segment(y= 5, yend=5, x=0, xend=50, color="red") +
theme(axis.text.y = element_markdown()) +
scale_y_discrete(labels=rev(unique(tm$papers_label)))
exp(1.15)
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message=FALSE, warning = FALSE, error = FALSE)
mean(x=c(5, 7))
x
# Variáveis Numéricas
x <- 5
x
mean(x<c(5, 7))
mean(x<-c(5, 7))
x=c(5, 7)
blogdown::serve_site()
# Ativar rtweet
#install.packages("rtweet") # somente uma vez
library(rtweet)
# ativar outros pacotes
library(tidyverse)
library(igraph)
library(broom)
bolsonaro_tweets<-search_tweets("bolsonaro", n=50, include_rts = TRUE)
create_token(app=app_name,
consumer_key=consumer_key,
consumer_secret=consumer_secret,
access_token = access_token,
access_secret = access_token_secret)
# Ativar rtweet
#install.packages("rtweet") # somente uma vez
library(rtweet)
app_name<-"Tiago Ventura"
consumer_key="RrVsiJGUywnVPM66jNT4fOpFp"
consumer_secret="IIBfGUOI0BoPwa2z984EpcmzP8uDcC9X0jU41kYmai7W4q2OAX"
access_token<- "59554649-vF4T4XCrLNtrT8xGUaBLrAEuoQ1obJKfoSRAF6wuZ"
access_token_secret<-"DhccPvb2klEGILzPK2XxApHfIrfDiNExOQpKMOR7oBuQA"
create_token(app=app_name,
consumer_key=consumer_key,
consumer_secret=consumer_secret,
access_token = access_token,
access_secret = access_token_secret)
bolsonaro_tweets<-search_tweets("bolsonaro", n=50, include_rts = TRUE)
# Checa se vieram retuites
bolsonaro_tweets$is_retweet
bolsonaro_tweets
dados_bolsonaro_stream <- stream_tweets("bolsonaro",
timeout = 10,
file_name = "bolsonaro.json") # adicione o tempo que voce quer coletar
rtweet_app()
dados_bolsonaro_stream <- stream_tweets("bolsonaro",
timeout = 10,
file_name = "bolsonaro.json") # adicione o tempo que voce quer coletar
getwd()
dados_bolsonaro_stream <- stream_tweets("bolsonaro",
timeout = 10,
file_name = "__bolsonaro.json") # adicione o tempo que voce quer coletar
